---
title: "Tableau de suivi"
author: "JcB"
date: "10/07/2014"
output: html_document
---

Ce document recense le suivi des RPU.

Remplacer __dx__ par le noms des données à analyser. Par défaut _dx_ fait référence aux données de l'année. __data__ est un nom générique pour l'ensemble des calculs.

```{r init}
load("~/Documents/Resural/Stat Resural/RPU_2014/rpu2014d0111_provisoire.Rda")
data <- dx

library("lubridate")
anc <- year(data$ENTREE[1])

```

Janvier 2015
============

- défaillance de Ste Odile. Ste Odile: plus de RPU depuis le 17/12. Message de Mr Nold: J’ai localisé l’origine du problème. Depuis le 18/12, la clinique St Odile nous envoie un fichier avec un nouveau numéro FINESS. En revanche je n’ai pas trouvé de trace ce numéro FINESS sur le site finess.sante.gouv.fr.. Ste Odile envoie des RPU anormaux depuis le 12/12/2014 où le n°FINESS est le n° jridique (670780204), alors que c'est le n°géographique qui est attendu. Le nombre de RPU avec ce mauvais N° est de l'ordre de 1 à 5 par jour. M. Combeau des cliniques de Strasbourg m’a informé que le nouveau numéro FINESS est une erreur de paramétrage. A partir de demain nous devrions à nouveau avoir les bon RPU. En revanche il ne pense pas pouvoir nous renvoyer les RPU entre le 17/12 et aujourd’hui.

- défaillance de Ste Anne: plus de RPU depuis le 22/12/204

- le reste sp.

Décembre 2014
=============

Correction des RPU de Novembre 2014 en provenance de Wissembourg. Il manquait environ 20 jours sur les 30 en raison d'un bug local (erreur de date). Wissemboug m'a renvoyé un fichier XML contenant tous les RPU du 1er janvier au 30 novembre 2014. Le fichier intitulé __RPU_670000272_141201(1).xml__ se trouve dans le dossier __/home/jcb/Documents/Resural/Stat Resural/Archives_Sagec/RPU2014_Wissembourg__. Il annule et remplace l'envoi du mois de Novembre. Analysé par le parser pour former les fichiers .CSV correspondant (NB corriger un bug du Parser pour qu'il intitule les fichiers avec des préfixes différents: RPU, DA et ACTES. Actuellement ces 3 fichiers ont le même nom).

Le fichier .csv doit être normalisé et réorganisé pour pouvoir être lié à la base annuelle. C'est l'objet du programme __wiss.Rmd__ qui est transposable à tout fichier parsé par cette méthode.

Au final, le fichier de novembre, la base du 1er janvier au 30 novembre 2014 et le fichier combiné 2013+2014 sont à jour au 1er décembre. Avec cette correction il y a un peu plus de 40.000 RPU pour le mois de novembre.

Ajout d'une fonction periode.pet$MOTIF __normalise.caracteres()__ dans __quot_utils.R__ qui corrige les caractères anormaux dans DP et MOTIF.

Travail pour l'ARS sur les pétards de la fin de l'année: __petards.Rmd__ à mettre en forme.

Création d'un fichier __Lubridate__ pour servir de mode d'emploi à cette librairie.



Novembre 2014
=============

Haguenau
--------

Infos du mois: la pédiatrie médicale de Haguenau n'est informatisée via dxcare que depuis le moiis de juillet 2014. Ceci explique les chiffres anormalement bas de 2013 (environ 15% des RPU contre 30% en oyenne départementale). Vérification:

```{r}
# tois les rpu de haguenau
hag <- dx[dx$FINESS == "Hag",] # dx = rpu2014d0111_provisoire
# rpu peédiatriques
ped.hag <- hag[hag$AGE < 18,]
rpu.hag <- tapply(as.Date(hag$ENTREE), month(as.Date(hag$ENTREE)), length)
rpu.ped.hag <- tapply(as.Date(ped.hag$ENTREE), month(as.Date(ped.hag$ENTREE)), length)
rpu.ped.hag * 100 / rpu.hag

```
       1        2        3        4        5        6        7        8        9       10       11 
10.97520 12.19512 14.42720 15.27963 14.73142 15.50095 28.38861 27.98032 34.23631 32.91071 34.58647

A partir du mois de juillet le % de rpu pediatriques atteint les 30%.

Wissembourg
-----------

Envoi d'un fichier XML avec les données du 1er janvier au 19 novembre 2014. Fichier transformé en csv et archivé dans /home/jcb/Documents/Resural/Stat Resural/Archives_Sagec/RPU2014_Wissembourg. Reste la maj dans le fichier maître à faire: supprimer les enregistrements de wissembourg entre le 1er javier et le 19 novembre et les remplacer par des derniers.

Depuis quelle date les établissements transmettent des données
--------------------------------------------------------------

```{r}
origin <- as.Date(tapply(as.Date(dx$ENTREE), factor(dx$FINESS), min), origin="1970-01-01")
a <- data.frame(names(origin), origin)
```
- Ste Anne: 2014-05-12
- Roosvelt: 2014-02-05
- Diaconat Strasbourg: 2014-02-01
- Pédiatrie Haguenau: 2014-07-01
- HUS (nouveaux RPU): 2014-10-10

Octobre 2014
============

L'évènement du mois est le passage en production du nouvelle méthodologie des HUS (développée par mr Lorenz) permettant une transmission exhaustive des RPU. La bascule se fait pour les données du 13 octobre:
```{}
 rj <- rpu_jour("2014-10-13")
 d <- rj[rj$FINESS=="Hus",]
tapply(as.Date(d$ENTREE), as.Date(d$ENTREE), length)

2014-10-06 2014-10-07 2014-10-08 2014-10-09 2014-10-10 2014-10-11 2014-10-12 
       139        415        422        425        465        436        462
```
On passe de 130 à 462 RPU/jour.

Deux FINESS nouveaux sont introduits: NHC et HTP. Pour l'instant les deux FINESS sont fusionnés en un seul. 

Août 2014
=========

Incorporation des fichiers de Juillet. Pas de problèmes notables sauf Diaconat Strasbourg qui n'envoie pas de données
Pb de serveur, je ne reçoit pas les RPU du diaconat -> relancer Nold
Parser XML terminé le 15/8. Voir avec Nold pour lasuite

Septembre 2014
==============

Le fichier __rpu2014d08.Rda__ est créé à partir des fichiers .csv allant du 8/8/2014 au 7/9/2014. Un trou à rattrapper pour Altkirch à partir du 20/8.

suivi des RPU: comment est saisi l'item motif, bilan du mois d'aout 2014. En progrès. Un seul établissement ne saisit pas (Hus) et 3 sont non conformes.

```{r}
h <- function(x){head(x,20)}
tapply(data$MOTIF, data$FINESS, h)

```
pas de saisie
------------

Ste Anne ? 1 seule réponse en novembre: "U359**"

pas conforme
------------
 
Sélestat
Colmar

Conforme:
---------
Mulhouse
Se Odile
Roosvelt
Saverne: ok mais bcp de non réponses
Wissembourg
Diaconat Mulhouse: sp
Diaconat Strasbourg
Guebwiller
Haguenau
HUS
3Fr (complétude = 2 %...)
Altkirch  (complétude = 17 %...)

suivi de la conformité
----------------------
c3f <- d11[d11$FINESS == "3Fr", "MOTIF"]
mean(is.na(c3f))
c3f[!is.na(c3f)]

alk <- d11[d11$FINESS == "Alk", "MOTIF"]
mean(is.na(alk))
alk[!is.na(alk)]

ane <- d11[d11$FINESS == "Ane", "MOTIF"]
mean(is.na(ane))
ane[!is.na(ane)]



suivi de la complétude
----------------------
Il faut corriger DESTINATION et ORIENTATION: si MODE_SORTIE = Domicile, alors les 2 items ne peuvent être remplis et se voient attribuer la valeur NA, ce qui provoque une erreur dans le décompte de ces 2 items. Pour éviter cela, on leur attribue la valeur "domicile" si MODE_SORTIE = Domicile.

```{r}

data$DESTINATION[data$MODE_SORTIE == "Domicile"] <- "Domicile"
data$ORIENTATION[data$MODE_SORTIE == "Domicile"] <- "Domicile"

pIsNa <- function(x){apply(is.na(x),2,mean)} # mean(is.na(x)) = % ne non réponses
a <- unique(data$FINESS) # liste des établissements
for(i in a){print(i); x <- pIsNa(data[data$FINESS==i,]); print((1-x)*100) }

# la fonction qui suit automatise la tâche et retourne l'inverse de la fonction h cad le % de réponses pour l'item, sous forme de dataframeun dataframe:
complet <- function(hop, data){
  j = 0;
  for(i in hop){
    x <- pIsNa(data[data$FINESS==i,]); 
    x <- (1-x)*100; # inverse de la fonction
    j = j+1
    if(j == 1)
      t = x
    else
      t = rbind(t,x)
  }
  t <- data.frame(hop,t)
  return(t)
}

# dataframe des complétudes par rubrique et par finess
q <- complet(a,data)


# fonction auxiliaire qui retourne la moyenne d'un vecteur x, arrondi à 2 décimales
arrondi <- function(x){round(mean(x, na.rm = TRUE), 2)}
# application: pour chaque rubrique calcule la moyenne de l'ensemble des Finess (les rubriques sont en colonnes)
apply(q[-1], 2, arrondi)

```
__q__ est un dataframe de 15 lignes et 21 colonnes

TODO: faire des radars: les établissements comme rayons et les rubriques comme intitulé du graphe.

Remarque pour 2013: on réduit de façon importante les NA sur ces 2 rubriques.

```{}
load("../RPU_2013/rpu2013d0112.Rda")
d1$DESTINATION <- as.character(d1$DESTINATION)
d1$DESTINATION[d1$MODE_SORTIE == "Domicile"] <- "Domicile"
d1$DESTINATION <- as.factor(d1$DESTINATION)
summary(d1$DESTINATION)
mean(is.na(d1$DESTINATION))

d1$ORIENTATION <- as.character(d1$ORIENTATION)
d1$ORIENTATION[d1$MODE_SORTIE == "Domicile"] <- "Domicile"
d1$ORIENTATION <- as.factor(d1$ORIENTATION)
summary(d1$ORIENTATION)
mean(is.na(d1$ORIENTATION))

Domicile      HAD      MCO      PSY      SLD      SSR     NA's 
  223155        5    71522     1173       27      102    48089 
[1] 0.1397639

CHIR Domicile    FUGUE      HDT       HO      MED     OBST      PSA      REA      REO       SC       SI     UHCD     NA's 
7738   223155        1      110       29    18449       96       52     1025       44     1420     1366    32169    58419 
[1] 0.1697866

```


Incohérence destination et mode de sortie
-----------------------------------------

On ne peut pas avoir simultanément MODE_SORTIE = Domicile et DESTINATION = MCO. Par exemple pour sptembre 2014:
```{}
data <- dx
table(data$DESTINATION, data$MODE_SORTIE)
     
      Domicile Mutation Transfert
  MCO       45     6446       360
  PSY        0       35        50
  SSR        0        6         8
```
Il y a 45 destinations incohérentes. Elle correspondent à Ste Anne et aux HUS:
```{}
a <- data[data$MODE_SORTIE=="Domicile" & data$DESTINATION=="MCO" & !is.na(data$DESTINATION) & !is.na(data$MODE_SORTIE),]
table(a$FINESS)

```



Juillet 2014
============

Le tableau de suivi du mois de Juin a révélé un grand nombre de RPU manquants. Ceci a pu être rapporté à un problème sur le serveur des HUS. Mr Nold a fait parvenir le 9/7/2014 un fichier .sql corrigé qui reprend tous les RPU du mois de juin. Ce fichier est intitulé __rpu_2014_06_dump.sql.gz__. Il est archivé sur le disque Toshiba dans le dossier __RPU Juin 2014 Correctif__ qui annule et remplace les données quotidienne du mois de juin 2014.

Ce fichier est copié dans le dossier __stat_resural/Archives_Sagec/dataQ__ et renommé __rpu_2014-06-00_dump.sql__ pour être traité. L'original se trouve dans le dossier __stat_resural/Archives_Sagec/dataQ/ArcjivesSQL/Juin_2014_sql/Juin_2014_corrige__

Ce fichier a été traité de la façon suivante:

```{}
source("Preparation/RPU Quotidiens/quot_utils.R")
# tranasformation du fichier .sql en dataframe
rj <- rpu_jour("2014-06-00")
# correctif car le fichier initial comporte des données du 1er juillet
a <- rj[as.Date(rj$ENTREE) < "2014-07-01",]
max(as.Date(a$ENTREE))
# vérification de l'exhaustivité
table(as.Date(a$ENTREE), a$FINESS)
# sauvegarde sous forme de fichier R
d06 <- a
rm(a, rj)
save(d06, file = "rpu2014d06.Rda")
# fusion avec les données des mois précédents
load("~/Documents/Resural/Stat Resural/RPU_2014/rpu2014d0105.Rda")
dx <- rbind(dx, d06)
save(dx, file = "rpu2014d0106.Rda")
# contrôle des dates
min(as.Date(dx$ENTREE))
max(as.Date(dx$ENTREE))
# Tableau des RPU par FINESS avec transformation du tableau croisé en dataframe. Noter l'emploi de la méthode as.data.frame.matrix qui conserve le tableau (si on utilise as.data.frame le résultat ne corresnd pas du tout aux attentes!)
rpu <- as.data.frame.matrix(table(as.Date(dx$ENTREE), factor(dx$FINESS)))
somme.lignes <- rowSums(rpu)
```

Le résultats final:

- 193.641 RPU au 30 juin
- manque SOS mains Strasbourg et Thann

Juin 2014
=========

Au 6/6 Ste Anne n'émet rien => vérifier

Essai d'utilisation de Xts
--------------------------
 On forme une table de contingence en croisant la date d'entrée et le Finess. Le croisement donne le total des RPU par jour pour un SU. Le tableau est transformé en dataframe par __as.data.frame.matrix__. La transformation en dataframe permet de préserver la nature des colonnes. On crée une colonne __date__ correspondant à chaque jour du mois que l'on ajoute au dataframe et cette nouvelle colonne est mise au format 'Date'. C'est elle qui servira d'index à l'objet xts. On crée également une colonne total qui est ajoutée au dataframe.
 
 Le dataframe est transformé en objet __xts__ qui peut être plotté. On ajoute la moyenne mobile avec __rollappy__ (j'ai essayé avec rollmean mais j'ai une erreur ?)
 
```{r xts_test}
library(xts)
data <- dx

t <- table(as.Date(data$ENTREE), data$FINESS) 
date <- rownames(t)
a <- as.data.frame.matrix(t)
a <- cbind(a, date)
a$date <- as.Date(a$date)
a$total <- rowSums(a[,1:14])
ts <- xts(a, order.by = a$date)

anc <- year(data$ENTREE[1])
plot(ts$total, main= paste0("Activité du mois de Mai ", anc), ylab="nombre de RPU", minor.ticks = FALSE)

lines(rollapply(ts$total, 7, mean), col="red")
legend("topleft", legend="Moyenne mobile", col="red", lty=1, bty="n")

plot(ts$total,minor.ticks=FALSE, col = "gray")
lines(rollapply(ts$total, 7, mean), col="red")

# essai d'agrandissement de la fenêtre:
plot(ts$total["2014-10/2014-12"],minor.ticks=FALSE, col = "gray")
lines(rollapply(ts$total["2014-09/2014-12"], 7, mean), col="red")

```
fonction dérivée

A partir du fichier habituel des RPU retourne un objet xts ayant autant de 
colonnes qu'il y a de SU dans d plus 2 colonnes supplémentaires:
- date de type 'Date' qui sert d'index à xts
- total nombre total de RPU par jour

d données RPU

rpu2xts <- function(d){
  library(xts)
  t <- table(as.Date(d$ENTREE), d$FINESS)
  date <- rownames(t)
  a <- as.data.frame.matrix(t)
  a <- cbind(a, date)
  a$date <- as.Date(a$date)
  a$total <- rowSums(a[,1:14])
  ts <- xts(a, order.by = a$date)
  ts
}

Sauvegarde de données de juin 
-----------------------------

date1 <- "2014-06-08"
date2 <- "2014-06-18"
p <- seq(as.Date(date1), as.Date(date2), 1)
for(i in 1:length(p)){
dx <- rpu_jour(p[i])
}
dx <- assemble(comment = FALSE)
min(as.Date(dx$ENTREE))
table(as.Date(dx$ENTREE), dx$FINESS)
d06 <- dx
save(d06, file = "rpu2014d06_Provisoire.Rda")


C3F - Mai 2014
==============

A partir du 16 mai 2014 la clinique des 3 frontières passe au n°Finess __680020096__. Ce changement provoque une erreur dans le fichier transmis par Mr Nold car les données de la clinique apparaissent deux fois: une fois sous "3Fr" et une fois sous "680020096". Les données sont corrigées jusqu'au 19/05 inclus. Anomalie signalée le 31/05/2014 , en attente.

Erreur corrigée à partir du 22/05/2014 mais 6 jours sont doublonnés, du 16/5 au 23/5/2014 inclu.

Algorithme de correction(12/06/2014):
- on isole les 6 jours concernés dans le datafame __c3f__
- on trie les lignes par ordre de date/heure d'entrée de sorte que tous les doublons se trouvent sur deux lignes consécutives
- on crée le dataframe __c3__ en ne retenant que les lignes impaires de c3f. En pratique on ne garde qu'une ligne sur 2 ce qui permet d'éliminer les doublons
- on forme un dataframe avec tous les enregistrements du mois de mai, sauf ceux correspondants à la C3F: __data_saufc3f__
- de la même façon on forme le dataframe complémentaire qui ne contient que les enregistrement de la C3F: __data_3fr__
- de data_3fr on retire tous les enregistrements correspondants aux jours litigieux, ce qui donne __data_3fr_sauf_doublons__
- on reforme un dataframe __data_corrige__ qui est la concaténation des lignes correspondant à la C3F moins les doublons
- on vérifie que tout est bon en faisant un table()
- on rebaptise le dataframe corrigé en __data__ et on le sauvegarde
- on recrée le dataframe __dx__ concaténation du mois de mai avec les autres mois de l'année et on sauvegarde le tout dans __rpu2014d0105.Rda__.

```{}
c3f <- data[as.Date(data$ENTREE) >= "2014-05-16" & as.Date(data$ENTREE) <= "2014-05-23" & data$FINESS == "3Fr",]
c3fo <- c3f[order(c3f$ENTREE),]
c3 <- c3fo[1,]
seq <- seq(3, nrow(c3fo), by=2)
for(i in seq){c3 <- rbind(c3, c3fo[i,])}
data_saufc3f <- data[data$FINESS != "3Fr",]
data_3fr <- data[data$FINESS == "3Fr",]
data_3fr_sauf_doublons <- data_3fr[as.Date(data_3fr$ENTREE) < "2014-05-16" | as.Date(data_3fr$ENTREE) > "2014-05-23",]
data_corrige <- rbind(data_saufc3f, data_3fr_corrige)
table(as.Date(data_corrige$ENTREE), data_corrige$FINESS)
data <- data_corrige
save(data, file="rpu2014data.Rda")
load("rpu2014d0104.Rda")
dx <- rbind(a, data)
save(dx, file="rpu2014d0105.Rda")

```
CCL: les données du mpois de Mai 2014 sont 'propres' à la date du 12 juin 2014.

Anomalies du mois de mai:

- Ste Anne a fait unessai du 12 au 16 mai, et semle être passé en production depuisle 28 mai 2014. A vérifier en juin.
- CH Alkirch: toujours des ratées dans la transmission: 1, 4, 11, 27, 29 mai
- CHM: 9, 10, 22 nb anormalement bas de assages
- Roosvelt: 13 mai nnb de RPU < 10
- CH Selestat: 13, 15, 16,17 moins de 5 RPU

- 158 346 RPU au 31 mai 2014. Comparaison avec 2013:

```{}
load("../RPU_2013/rpu2013d0112.Rda")
d_2013_au31mai <- d1[as.Date(d1$ENTREE) < "2013-06-01",]
nrow(d_2013au31mai)

# 137 612
```
soit __20734__ RPU de plus soit environ 400.000 RPU en 2014.

Les chiffres de référence de passages figurent dans le fichier [SAE 2013](home/jcb/Documents/Resural/Stat Resural/RPU_2013/Data/SAE2013). La somme des passages est égale à __493321__, non comptés les SOS mains.

Au 11/11/2014, les sos mains représentent 8762 passages:
```{r}
m1 <- dx[dx$FINESS == "Dts", "ENTREE"]
m2 <- dx[dx$FINESS == "Ros", "ENTREE"]
length(m1) + length(m2)

n.rpu.su <- nrow(dx) - length(m1) - length(m2)
n.rpu.su
```


Rajouter:
```{}
Résumé d'activité
Radar
```
